---
---

@misc{wu2025clarifycoderclarificationawarefinetuningprogrammatic,
      title={ClarifyCoder: Clarification-Aware Fine-Tuning for Programmatic Problem Solving}, 
      author={Jie JW Wu and Manav Chaudhary and Davit Abrahamyan and Arhaan Khaku and Anjiang Wei and Fatemeh H. Fard},
      year={2025},
      eprint={2504.16331},
      archivePrefix={arXiv},
      primaryClass={cs.SE},
      url={https://arxiv.org/abs/2504.16331},
      additional_info={Under review at the International Conference on Software Engineering},
      preview={ClarifyCoder-.png},
}

@inproceedings{chaudhary-etal-2024-towards,
    title = "Towards Understanding the Robustness of {LLM}-based Evaluations under Perturbations",
    author = "Chaudhary, Manav  and
      Gupta, Harshit  and
      Bhat, Savita  and
      Varma, Vasudeva",
    editor = "Lalitha Devi, Sobha  and
      Arora, Karunesh",
    booktitle = "Proceedings of the 21st International Conference on Natural Language Processing (ICON)",
    month = dec,
    year = "2024",
    address = "AU-KBC Research Centre, Chennai, India",
    publisher = "NLP Association of India (NLPAI)",
    url = "https://aclanthology.org/2024.icon-1.22/",
    pages = "197--205",
    additional_info={},
    preview={perturbations_in_action.png},
    abstract = "Traditional evaluation metrics like BLEU and ROUGE fall short when capturing the nuanced qualities of generated text, particularly when there is no single ground truth. In this paper, we explore the potential of Large Language Models (LLMs), specifically Google Gemini 1, to serve as automatic evaluators for non-standardized metrics in summarization and dialog-based tasks. We conduct experiments across multiple prompting strategies to examine how LLMs fare as quality annotators when compared with human judgments on the SummEval and USR datasets, asking the model to generate both a score as well as a justification for the score. Furthermore, we explore the robustness of the LLM evaluator by using perturbed inputs. Our findings suggest that while LLMs show promise, their alignment with human evaluators is limited, they are not robust against perturbations and significant improvements are required for their standalone use as reliable evaluators for subjective metrics."
}

@inproceedings{chaudhary-etal-2024-brainstorm,
    title = "{B}rain{S}torm @ i{REL} at {\#}{SMM}4{H} 2024: Leveraging Translation and Topical Embeddings for Annotation Detection in Tweets",
    author = "Chaudhary, Manav  and
      Gupta, Harshit  and
      Varma, Vasudeva",
    editor = "Xu, Dongfang  and
      Gonzalez-Hernandez, Graciela",
    booktitle = "Proceedings of the 9th Social Media Mining for Health Research and Applications (SMM4H 2024) Workshop and Shared Tasks",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.smm4h-1.28/",
    pages = "121--123",
    additional_info={},
    preview={brainstorm.png},
    abstract = "The proliferation of LLMs in various NLP tasks has sparked debates regarding their reliability, particularly in annotation tasks where biases and hallucinations may arise. In this shared task, we address the challenge of distinguishing annotations made by LLMs from those made by human domain experts in the context of COVID-19 symptom detection from tweets in Latin American Spanish. This paper presents BrainStorm @ iREL`s approach to the {\#}SMM4H 2024 Shared Task, leveraging the inherent topical information in tweets, we propose a novel approach to identify and classify annotations, aiming to enhance the trustworthiness of annotated data."
}

@inproceedings{gupta-etal-2024-irel,
    title = "i{REL} at {S}em{E}val-2024 Task 9: Improving Conventional Prompting Methods for Brain Teasers",
    author = "Gupta, Harshit  and
      Chaudhary, Manav  and
      Subramanian, Shivansh  and
      Raha, Tathagata  and
      Varma, Vasudeva",
    editor = {Ojha, Atul Kr.  and
      Do{\u{g}}ru{\"o}z, A. Seza  and
      Tayyar Madabushi, Harish  and
      Da San Martino, Giovanni  and
      Rosenthal, Sara  and
      Ros{\'a}, Aiala},
    booktitle = "Proceedings of the 18th International Workshop on Semantic Evaluation (SemEval-2024)",
    month = jun,
    year = "2024",
    address = "Mexico City, Mexico",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.semeval-1.250/",
    doi = "10.18653/v1/2024.semeval-1.250",
    pages = "1758--1766",
    additional_info={},
    preview={1736966140144.png},
    abstract = "This paper describes our approach for SemEval-2024 Task 9: BRAINTEASER: A Novel Task Defying Common Sense. The BRAINTEASER task comprises multiple-choice Question Answering designed to evaluate the models' lateral thinking capabilities. It consists of Sentence Puzzle and Word Puzzle subtasks that require models to defy default commonsense associations and exhibit unconventional thinking. We propose a unique strategy to improve the performance of pre-trained language models, notably the Gemini 1.0 Pro Model, in both subtasks. We employ static and dynamic few-shot prompting techniques and introduce a model-generated reasoning strategy that utilizes the LLM`s reasoning capabilities to improve performance. Our approach demonstrated significant improvements, showing that it performed better than the baseline models by a considerable margin but fell short of performing as well as the human annotators, thus highlighting the efficacy of the proposed strategies."
}

@misc{vardhan2023imetreincorporatingmarkersentity,
      title={iMETRE: Incorporating Markers of Entity Types for Relation Extraction}, 
      author={N Harsha Vardhan and Manav Chaudhary},
      year={2023},
      eprint={2307.00132},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2307.00132},
      additional_info={Accepted at The 4th Workshop on Knowledge Discovery from Unstructured Data in Financial Services (KDF) at SIGIR (non-archival)},
      preview={EntityPairs.png},
}
